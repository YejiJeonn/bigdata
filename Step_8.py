# -*- coding: utf-8 -*-
"""ê¸°ë§ í”„ë¡œì íŠ¸_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O0KeI715k5J6pchBlSbdKnnJQH_1j65X
"""

!apt-get update -qq
!apt-get install -y fonts-nanum
!fc-cache -fv

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl

# ë‚˜ëˆ”í°íŠ¸ ë¡œë“œ
font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
fm.fontManager.addfont(font_path)

plt.rc('font', family='NanumGothic')
mpl.rcParams['axes.unicode_minus'] = False

import pandas as pd

# ====== 1. KOSPI / SPX ë°ì´í„° ë‹¤ìš´ë¡œë“œ ======
kospi_url = "https://stooq.com/q/d/l/?s=^kospi&i=m"
spx_url   = "https://stooq.com/q/d/l/?s=^spx&i=m"

kospi_df = pd.read_csv(kospi_url, parse_dates=['Date'])
spx_df   = pd.read_csv(spx_url,   parse_dates=['Date'])

# ====== 2. ê¸°ê°„ í•„í„°ë§ ======
start_date = "2019-01-01"
kospi_recent = kospi_df[kospi_df['Date'] >= start_date].copy()
spx_recent   = spx_df[spx_df['Date'] >= start_date].copy()

# ====== 3. ìˆ˜ìµë¥  ê³„ì‚° ======
kospi_recent["KOSPI_Return"] = kospi_recent["Close"].pct_change()
spx_recent["SPX_Return"] = spx_recent["Close"].pct_change()

# ====== 4. ë‚ ì§œ ê¸°ì¤€ merge ======
data = pd.merge(
    kospi_recent[["Date", "KOSPI_Return"]],
    spx_recent[["Date", "SPX_Return"]],
    on="Date",
    how="inner"
).dropna()

data.set_index("Date", inplace=True)

print("data í™•ì¸")
print(data.head())
print(data.tail())
print("data ê°œìˆ˜:", len(data))

# ====== 5. train / test ë¶„ë¦¬ ======
train = data[:'2023-12-31']
test  = data['2024-01-01':]

print("\nTrain:", train.index[0], "~", train.index[-1])
print("Test:", test.index[0], "~", test.index[-1])

# ëª¨ë¸1. ì„ í˜• íšŒê·€

from sklearn.linear_model import LinearRegression

X_train = train[['SPX_Return']]
y_train = train['KOSPI_Return']

X_test  = test[['SPX_Return']]
y_test  = test['KOSPI_Return']

lr_model = LinearRegression().fit(X_train, y_train)
lr_pred  = lr_model.predict(X_test)

print("ì„ í˜•íšŒê·€ ê³„ìˆ˜:", lr_model.coef_, "ì ˆí¸:", lr_model.intercept_)

# ëª¨ë¸2. VAR (Vector Auttoregression)

# from statsmodels.tsa.api import VAR

# var_train = train.copy()
# model_var = VAR(var_train)
# var_result = model_var.fit(maxlags=3)

# var_pred = var_result.forecast(var_train.values[-3:], steps=len(test))
# var_pred_df = pd.DataFrame(var_pred, index=test.index, columns=['SPX_pred','KOSPI_pred'])

from statsmodels.tsa.vector_ar.var_model import VAR

# VAR ëª¨ë¸ í•™ìŠµ
var_model = VAR(train)
var_result = var_model.fit(maxlags=4)  # ì ì ˆíˆ ìˆ˜ì • ê°€ëŠ¥ (AIC ê¸°ë°˜ ì„ íƒ ê°€ëŠ¥)

# ì˜ˆì¸¡ ìˆ˜í–‰
var_forecast = var_result.forecast(train.values, steps=len(test))

# ì˜ˆì¸¡ê°’ ë°°ì—´ â†’ DataFrame ë³€í™˜
var_pred_df = pd.DataFrame(var_forecast, index=test.index, columns=train.columns)

# ìš°ë¦¬ëŠ” KOSPIë§Œ ì‚¬ìš©
var_kospi_pred = var_pred_df["KOSPI_Return"]

# ëª¨ë¸3. LSTM (SPXë¡œ KOSPI ì˜ˆì¸¡)

from sklearn.preprocessing import MinMaxScaler
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# 1) ìŠ¤ì¼€ì¼ë§
scaler = MinMaxScaler()
scaled = scaler.fit_transform(data)

scaled_df = pd.DataFrame(scaled, index=data.index, columns=data.columns)

# 2) ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_seq(dataset, window=12):
    X, y = [], []
    for i in range(window, len(dataset)):
        X.append(dataset[i-window:i, 0])  # SPX_Return ì…ë ¥
        y.append(dataset[i, 1])           # KOSPI_Return ì¶œë ¥
    return np.array(X), np.array(y)

window = 12
X, y = create_seq(scaled_df.values, window)

split = len(train)
X_train, X_test = X[:split-window], X[split-window:]
y_train, y_test_lstm = y[:split-window], y[split-window:]

# reshape for LSTM
X_train = X_train.reshape(-1, window, 1)
X_test  = X_test.reshape(-1, window, 1)

# 3) LSTM ëª¨ë¸ êµ¬ì„±
lstm_model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(window,1)),
    LSTM(32),
    Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mse')
lstm_model.fit(X_train, y_train, epochs=30, batch_size=8, verbose=1)

# 4) ì˜ˆì¸¡
lstm_pred = lstm_model.predict(X_test)

# ì—­ìŠ¤ì¼€ì¼ë§ìš©

import numpy as np

# target ì»¬ëŸ¼ ì¸ë±ìŠ¤ (KOSPI_Return)
target_idx = scaled_df.columns.get_loc("KOSPI_Return")  # ë³´í†µ 1ì¼ ê²ƒ

# ì˜ˆì¸¡ê°’ ì—­ìŠ¤ì¼€ì¼ë§ìš© dummy ë°°ì—´
dummy_pred = np.zeros((len(lstm_pred), scaled_df.shape[1]))
dummy_pred[:, target_idx] = lstm_pred.reshape(-1)

inv_all = scaler.inverse_transform(dummy_pred)
lstm_pred_inv = inv_all[:, target_idx]  # KOSPI_Returnë§Œ ì¶”ì¶œ

# ëª¨ë¸ë³„ ì˜ˆì¸¡ ì •í™•ë„ ë¹„êµ

def evaluate(y_true, y_pred, name=""):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    print(f"\nğŸ“Œ {name} ëª¨ë¸ ì •í™•ë„")
    print("MAE :", mae)
    print("MSE :", mse)
    print("RMSE:", rmse)

evaluate(test["KOSPI_Return"], lr_pred, "ì„ í˜•íšŒê·€")
evaluate(test["KOSPI_Return"], var_kospi_pred, "VAR")
evaluate(test["KOSPI_Return"], lstm_pred_inv[:len(test)], "LSTM")

# ê·¸ë˜í”„ ë¹„êµ ì¶œë ¥

plt.figure(figsize=(12,6))
plt.plot(test.index, test["KOSPI_Return"], label="ì‹¤ì œ KOSPI", linewidth=2)
plt.plot(test.index, lr_pred, label="Linear Regression ì˜ˆì¸¡")
plt.plot(test.index, var_kospi_pred, label="VAR ì˜ˆì¸¡")
plt.plot(test.index, lstm_pred_inv[:len(test)], label="LSTM ì˜ˆì¸¡")
plt.title("ë¯¸êµ­ì¥(S&P500) ê¸°ë°˜ í•œêµ­ì¥(KOSPI) ì˜ˆì¸¡ ë¹„êµ")
plt.xlabel("ë‚ ì§œ")
plt.ylabel("KOSPI Return")
plt.legend()
plt.grid(True)
plt.show()